{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîç Spice Image Classification - Inference\n",
    "\n",
    "This notebook demonstrates how to use the trained model for inference on new images.\n",
    "\n",
    "## üìã Steps:\n",
    "1. Load trained model\n",
    "2. Single image prediction\n",
    "3. Batch prediction\n",
    "4. Visualize predictions\n",
    "5. Grad-CAM visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.10.0+cu128\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "from predict import SpicePredictor\n",
    "from config import Config\n",
    "\n",
    "# Enable inline plotting\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Device: {Config.DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Set Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SET YOUR PATHS HERE\n",
    "# ============================================================\n",
    "\n",
    "# Path to trained model\n",
    "MODEL_PATH = \"./outputs/best_model.pt\"  # CHANGE THIS!\n",
    "\n",
    "# Path to class names JSON\n",
    "CLASS_NAMES_PATH = \"./outputs/class_names.json\"  # CHANGE THIS!\n",
    "\n",
    "# Path to test image (for single prediction)\n",
    "TEST_IMAGE_PATH = \"./test_image.jpg\"  # CHANGE THIS!\n",
    "\n",
    "# Path to test images folder (for batch prediction)\n",
    "TEST_FOLDER_PATH = \"./test_images\"  # CHANGE THIS!\n",
    "\n",
    "# ============================================================\n",
    "\n",
    "print(f\"Model: {MODEL_PATH}\")\n",
    "print(f\"Classes: {CLASS_NAMES_PATH}\")\n",
    "print(f\"Test Image: {TEST_IMAGE_PATH}\")\n",
    "print(f\"Test Folder: {TEST_FOLDER_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictor\n",
    "print(\"Loading model...\")\n",
    "predictor = SpicePredictor(\n",
    "    model_path=MODEL_PATH,\n",
    "    class_names_path=CLASS_NAMES_PATH\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Model loaded successfully!\")\n",
    "print(f\"Number of classes: {predictor.num_classes}\")\n",
    "print(f\"Classes: {predictor.class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Single Image Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict single image\n",
    "result = predictor.predict_image(TEST_IMAGE_PATH, top_k=5)\n",
    "\n",
    "# Print results\n",
    "predictor.predict_and_print(TEST_IMAGE_PATH, top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize prediction\n",
    "predictor.visualize_prediction(\n",
    "    TEST_IMAGE_PATH, \n",
    "    output_path='prediction_viz.png',\n",
    "    top_k=5\n",
    ")\n",
    "\n",
    "# Display\n",
    "from IPython.display import Image as IPImage\n",
    "IPImage(filename='prediction_viz.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Access Prediction Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get prediction details\n",
    "print(\"Prediction Details:\")\n",
    "print(f\"Image: {result['image_path']}\")\n",
    "print(f\"Predicted Class: {result['predicted_class']}\")\n",
    "print(f\"Confidence: {result['confidence']*100:.2f}%\")\n",
    "\n",
    "print(\"\\nTop-5 Predictions:\")\n",
    "for i, pred in enumerate(result['top_k_predictions'], 1):\n",
    "    print(f\"  {i}. {pred['class']:<20} - {pred['confidence_percent']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Batch Prediction (Multiple Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict all images in folder\n",
    "print(f\"Predicting images in {TEST_FOLDER_PATH}...\\n\")\n",
    "\n",
    "try:\n",
    "    results = predictor.predict_folder(TEST_FOLDER_PATH, top_k=3)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Predicted {len(results)} images\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Make sure TEST_FOLDER_PATH contains images!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Visualize Multiple Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize multiple predictions in a grid\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def visualize_predictions_grid(results, max_images=9):\n",
    "    \"\"\"Visualize predictions in a grid\"\"\"\n",
    "    n_images = min(len(results), max_images)\n",
    "    rows = int(n_images ** 0.5)\n",
    "    cols = (n_images + rows - 1) // rows\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols*4, rows*4))\n",
    "    if n_images == 1:\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.ravel()\n",
    "    \n",
    "    for idx, result in enumerate(results[:n_images]):\n",
    "        # Load image\n",
    "        img = Image.open(result['image_path'])\n",
    "        \n",
    "        # Display\n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].set_title(\n",
    "            f\"{result['predicted_class']}\\n\"\n",
    "            f\"Confidence: {result['confidence']*100:.1f}%\",\n",
    "            fontsize=10, fontweight='bold'\n",
    "        )\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for idx in range(n_images, len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('predictions_grid.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize if we have results\n",
    "try:\n",
    "    if 'results' in locals() and len(results) > 0:\n",
    "        visualize_predictions_grid(results, max_images=9)\n",
    "except:\n",
    "    print(\"Run batch prediction first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Grad-CAM Visualization (Advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grad-CAM visualization to see what the model focuses on\n",
    "from gradcam import GradCAM, get_target_layer\n",
    "from dataset_utils import get_transforms\n",
    "from model import load_model_for_inference\n",
    "\n",
    "# Load model for Grad-CAM\n",
    "model = load_model_for_inference(MODEL_PATH, predictor.num_classes)\n",
    "\n",
    "# Get target layer\n",
    "target_layer = get_target_layer(model, Config.MODEL_NAME)\n",
    "\n",
    "# Create Grad-CAM\n",
    "gradcam = GradCAM(model, target_layer)\n",
    "\n",
    "# Generate visualization\n",
    "transform = get_transforms('test')\n",
    "cam, pred_class, pred_prob = gradcam.visualize(\n",
    "    TEST_IMAGE_PATH,\n",
    "    transform,\n",
    "    output_path='gradcam_output.png'\n",
    ")\n",
    "\n",
    "# Display\n",
    "IPImage(filename='gradcam_output.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Interactive Prediction Widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive widget for file upload and prediction\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "def predict_uploaded_image(change):\n",
    "    \"\"\"Predict when image is uploaded\"\"\"\n",
    "    # Get uploaded file\n",
    "    uploaded_file = list(change['new'].values())[0]\n",
    "    content = uploaded_file['content']\n",
    "    \n",
    "    # Save temporarily\n",
    "    temp_path = 'temp_upload.jpg'\n",
    "    with open(temp_path, 'wb') as f:\n",
    "        f.write(content)\n",
    "    \n",
    "    # Predict\n",
    "    predictor.predict_and_print(temp_path, top_k=5)\n",
    "    predictor.visualize_prediction(temp_path, 'upload_prediction.png', top_k=5)\n",
    "    \n",
    "    # Display\n",
    "    display(IPImage(filename='upload_prediction.png'))\n",
    "\n",
    "# Create upload widget\n",
    "upload_widget = widgets.FileUpload(\n",
    "    accept='image/*',\n",
    "    multiple=False,\n",
    "    description='Upload Image'\n",
    ")\n",
    "upload_widget.observe(predict_uploaded_image, names='value')\n",
    "\n",
    "print(\"Upload an image to predict:\")\n",
    "display(upload_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîü Compare Predictions Across Different Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare predictions for multiple images side-by-side\n",
    "import pandas as pd\n",
    "\n",
    "def create_comparison_table(results):\n",
    "    \"\"\"Create comparison table for predictions\"\"\"\n",
    "    data = []\n",
    "    for result in results:\n",
    "        data.append({\n",
    "            'Image': Path(result['image_path']).name,\n",
    "            'Predicted Class': result['predicted_class'],\n",
    "            'Confidence': f\"{result['confidence']*100:.2f}%\",\n",
    "            'Top-2': result['top_k_predictions'][1]['class'] if len(result['top_k_predictions']) > 1 else 'N/A',\n",
    "            'Top-2 Conf': f\"{result['top_k_predictions'][1]['confidence_percent']:.2f}%\" if len(result['top_k_predictions']) > 1 else 'N/A'\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Create comparison if we have batch results\n",
    "try:\n",
    "    if 'results' in locals() and len(results) > 0:\n",
    "        comparison_df = create_comparison_table(results)\n",
    "        print(\"\\nPrediction Comparison:\")\n",
    "        display(comparison_df)\n",
    "        \n",
    "        # Save to CSV\n",
    "        comparison_df.to_csv('prediction_comparison.csv', index=False)\n",
    "        print(\"\\n‚úì Saved to prediction_comparison.csv\")\n",
    "except:\n",
    "    print(\"Run batch prediction first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Summary\n",
    "\n",
    "You've successfully used the trained model for inference!\n",
    "\n",
    "### What you can do:\n",
    "- ‚úì Predict single images\n",
    "- ‚úì Batch predict multiple images\n",
    "- ‚úì Visualize predictions with confidence scores\n",
    "- ‚úì Generate Grad-CAM visualizations\n",
    "- ‚úì Use interactive widget for uploads\n",
    "\n",
    "### Files generated:\n",
    "- `prediction_viz.png` - Single prediction visualization\n",
    "- `predictions_grid.png` - Grid of multiple predictions\n",
    "- `gradcam_output.png` - Grad-CAM visualization\n",
    "- `prediction_comparison.csv` - Comparison table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (research)",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
