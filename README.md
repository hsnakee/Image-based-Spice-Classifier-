# ğŸŒ¶ï¸ Spice Image Classification Pipeline

Ai Assitant used : Claude Sonet
IDE : Pycharm

A production-ready, deep learning pipeline for multi-class spice image classification using PyTorch and transfer learning.

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## ğŸ“‹ Table of Contents
- [Features](#features)
- [Dataset Structure](#dataset-structure)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Usage](#usage)
  - [Training](#training)
  - [Inference](#inference)
  - [Jupyter Notebook](#jupyter-notebook)
- [Model Architecture](#model-architecture)
- [Configuration](#configuration)
- [Output Artifacts](#output-artifacts)
- [Results](#results)
- [Project Structure](#project-structure)
- [Advanced Features](#advanced-features)
- [Troubleshooting](#troubleshooting)
- [Citation](#citation)
- [License](#license)

## âœ¨ Features

### Core Features
- âœ… **Transfer Learning**: Support for ResNet50, EfficientNet-B0/B3, ConvNeXt-Tiny
- âœ… **Automatic Mixed Precision (AMP)**: Faster training with lower memory usage
- âœ… **Data Augmentation**: Comprehensive augmentation pipeline
- âœ… **Class Imbalance Handling**: Weighted loss for imbalanced datasets
- âœ… **Early Stopping**: Prevents overfitting with configurable patience
- âœ… **Learning Rate Scheduling**: Multiple scheduler options
- âœ… **Reproducible Results**: Fixed seeds for deterministic training

### Evaluation & Visualization
- ğŸ“Š **Comprehensive Metrics**: Accuracy, Precision, Recall, F1, ROC-AUC
- ğŸ“ˆ **Training Curves**: Loss and accuracy plots
- ğŸ”¥ **Confusion Matrix**: Detailed per-class performance
- ğŸ“‰ **ROC Curves**: Multi-class ROC analysis
- ğŸ¨ **Class Distribution**: Visual analysis of dataset balance

### Bonus Features
- ğŸ” **Grad-CAM Visualization**: See what the model focuses on
- ğŸ¯ **Misclassified Samples**: Identify and visualize errors
- ğŸ“ **TensorBoard Logging**: Real-time training monitoring
- ğŸš€ **Batch Inference**: Predict on multiple images efficiently

## ğŸ“ Dataset Structure

The pipeline expects a folder-per-class structure:

```
dataset_root/
â”œâ”€â”€ Asafoetida/
â”‚   â”œâ”€â”€ image001.jpg
â”‚   â”œâ”€â”€ image002.jpg
â”‚   â””â”€â”€ ...
â”œâ”€â”€ BayLeaf/
â”‚   â”œâ”€â”€ image001.jpg
â”‚   â”œâ”€â”€ image002.jpg
â”‚   â””â”€â”€ ...
â”œâ”€â”€ BlackCardamom/
â”‚   â””â”€â”€ ...
â””â”€â”€ ... (other spice classes)
```

**Supported formats**: `.jpg`, `.jpeg`, `.png`, `.bmp`, `.tiff`

## ğŸš€ Installation

### Prerequisites
- Python 3.8 or higher
- CUDA-capable GPU (recommended, but not required)

### Step 1: Clone the Repository
```bash
git clone https://github.com/yourusername/spice-classification.git
cd spice-classification
```

### Step 2: Create Virtual Environment (Recommended)
```bash
# Using conda
conda create -n spice-classifier python=3.9
conda activate spice-classifier

# OR using venv
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### Step 3: Install Dependencies
```bash
pip install -r requirements.txt
```

### Step 4: Verify Installation
```python
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA Available: {torch.cuda.is_available()}')"
```

## ğŸ¯ Quick Start

### Training (5 minutes setup)
```bash
python train.py \
    --dataset_path /path/to/spice/dataset \
    --output_path ./outputs
```

### Inference (Single Image)
```bash
python predict.py \
    --model ./outputs/best_model.pt \
    --classes ./outputs/class_names.json \
    --image test_image.jpg \
    --visualize
```

## ğŸ“– Usage

### Training

#### Basic Training
```bash
python train.py \
    --dataset_path /path/to/dataset \
    --output_path ./results
```

#### Jupyter Notebook Training
See `train_notebook.ipynb` for interactive training:

```python
# In Jupyter notebook
from train import main

# Set your paths
dataset_path = "/path/to/spice/dataset"
output_path = "./outputs"

# Run training
main(dataset_path, output_path)
```

#### Configuration
Edit `config.py` to customize training:

```python
# Model selection
Config.MODEL_NAME = 'efficientnet_b0'  # Options: resnet50, efficientnet_b0, efficientnet_b3, convnext_tiny

# Training hyperparameters
Config.BATCH_SIZE = 32
Config.NUM_EPOCHS = 50
Config.LEARNING_RATE = 0.001

# Data splits
Config.TRAIN_RATIO = 0.70
Config.VAL_RATIO = 0.15
Config.TEST_RATIO = 0.15

# Enable/disable features
Config.USE_MIXED_PRECISION = True
Config.EARLY_STOPPING = True
Config.USE_CLASS_WEIGHTS = True
```

### Inference

#### Single Image Prediction
```bash
python predict.py \
    --model outputs/best_model.pt \
    --classes outputs/class_names.json \
    --image spice_sample.jpg \
    --top_k 5
```

#### Visualized Prediction
```bash
python predict.py \
    --model outputs/best_model.pt \
    --classes outputs/class_names.json \
    --image spice_sample.jpg \
    --visualize \
    --output prediction_viz.png
```

#### Batch Prediction (Folder)
```bash
python predict.py \
    --model outputs/best_model.pt \
    --classes outputs/class_names.json \
    --folder test_images/ \
    --top_k 3
```

#### Programmatic Usage
```python
from predict import SpicePredictor

# Initialize predictor
predictor = SpicePredictor(
    model_path='outputs/best_model.pt',
    class_names_path='outputs/class_names.json'
)

# Single prediction
result = predictor.predict_image('spice.jpg', top_k=5)
print(f"Predicted: {result['predicted_class']}")
print(f"Confidence: {result['confidence']*100:.2f}%")

# Batch prediction
results = predictor.predict_folder('test_images/', top_k=5)

# Visualize
predictor.visualize_prediction('spice.jpg', 'output.png')
```

## ğŸ—ï¸ Model Architecture

### Supported Models

| Model | Parameters | Image Size | Best For |
|-------|-----------|------------|----------|
| **ResNet50** | 25.6M | 224Ã—224 | Balanced performance |
| **EfficientNet-B0** | 5.3M | 224Ã—224 | Lightweight, fast |
| **EfficientNet-B3** | 12M | 300Ã—300 | Higher accuracy |
| **ConvNeXt-Tiny** | 28.6M | 224Ã—224 | State-of-the-art |

### Transfer Learning Strategy
1. **Phase 1**: Freeze backbone, train classifier (5 epochs)
2. **Phase 2**: Unfreeze backbone, fine-tune all layers (remaining epochs)
3. **Learning Rate**: Reduced by 10Ã— when unfreezing backbone

## âš™ï¸ Configuration

### Key Configuration Options

```python
# config.py

# Model Configuration
MODEL_NAME = 'efficientnet_b0'
IMAGE_SIZE = 224
NUM_CLASSES = 19  # Auto-detected

# Training Settings
BATCH_SIZE = 32
NUM_EPOCHS = 50
LEARNING_RATE = 0.001
WEIGHT_DECAY = 1e-4

# Optimization
OPTIMIZER = 'adam'  # adam, sgd, adamw
SCHEDULER = 'reduce_on_plateau'  # reduce_on_plateau, cosine, step
USE_MIXED_PRECISION = True

# Early Stopping
EARLY_STOPPING = True
EARLY_STOPPING_PATIENCE = 10

# Augmentation
AUGMENTATION = {
    'random_horizontal_flip': 0.5,
    'random_vertical_flip': 0.3,
    'random_rotation': 15,
    'color_jitter': {...}
}
```

## ğŸ“¤ Output Artifacts

After training, the following files are generated in the output directory:

```
outputs/
â”œâ”€â”€ best_model.pt                  # Best model checkpoint
â”œâ”€â”€ final_model.pt                 # Final epoch model
â”œâ”€â”€ training_history.csv           # Training logs
â”œâ”€â”€ config.json                    # Training configuration
â”œâ”€â”€ class_names.json              # Class mapping
â”œâ”€â”€ test_metrics.json             # Test set metrics
â”‚
â”œâ”€â”€ Visualizations:
â”œâ”€â”€ training_curves.png           # Loss & accuracy curves
â”œâ”€â”€ confusion_matrix.png          # Confusion matrix heatmap
â”œâ”€â”€ roc_curves.png               # Multi-class ROC curves
â”œâ”€â”€ per_class_metrics.png        # Per-class performance
â”œâ”€â”€ class_distribution.png       # Dataset statistics
â”œâ”€â”€ augmented_samples.png        # Sample augmentations
â””â”€â”€ gradcam_comparison.png       # Grad-CAM visualizations
```

## ğŸ“Š Results

### Expected Performance
On the 19-class spice dataset with proper training:

| Metric | Expected Range |
|--------|---------------|
| **Test Accuracy** | 85-95% |
| **F1 Score (Macro)** | 0.83-0.93 |
| **Training Time** | 15-30 min (GPU) |

### Sample Output

```
=================================================================
TEST SET RESULTS
=================================================================
Accuracy:           0.9245
Precision (macro):  0.9187
Recall (macro):     0.9156
F1 Score (macro):   0.9168
=================================================================
```

## ğŸ—‚ï¸ Project Structure

```
spice-classification/
â”‚
â”œâ”€â”€ train.py                 # Main training script
â”œâ”€â”€ predict.py              # Inference script
â”œâ”€â”€ config.py               # Configuration settings
â”œâ”€â”€ model.py                # Model architectures
â”œâ”€â”€ dataset_utils.py        # Data loading & preprocessing
â”œâ”€â”€ evaluation.py           # Metrics & visualization
â”œâ”€â”€ gradcam.py             # Grad-CAM implementation
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ train_notebook.ipynb      # Training in Jupyter
â”‚   â””â”€â”€ inference_notebook.ipynb  # Inference examples
â”‚
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ README.md              # This file
â””â”€â”€ LICENSE                # License file
```

## ğŸ¨ Advanced Features

### Grad-CAM Visualization

Visualize model attention:

```python
from gradcam import GradCAM, get_target_layer, visualize_multiple_images
from model import load_model_for_inference

# Load model
model = load_model_for_inference('outputs/best_model.pt', num_classes=19)

# Get target layer
target_layer = get_target_layer(model, 'efficientnet_b0')

# Create Grad-CAM
gradcam = GradCAM(model, target_layer)

# Visualize
gradcam.visualize('spice.jpg', transform, 'gradcam_output.png')
```

### Misclassified Samples Analysis

```python
from evaluation import find_misclassified_samples, visualize_misclassified

# Find misclassified samples
misclassified = find_misclassified_samples(
    model, test_loader, class_names, num_samples=20
)

# Visualize
visualize_misclassified(misclassified, 'misclassified.png')
```

### TensorBoard Logging

```bash
# Start TensorBoard
tensorboard --logdir outputs/tensorboard_logs

# Open browser to http://localhost:6006
```

## ğŸ”§ Troubleshooting

### Common Issues

**1. CUDA Out of Memory**
```python
# Reduce batch size in config.py
Config.BATCH_SIZE = 16  # or 8
```

**2. Low Accuracy**
- Ensure sufficient training data (>50 images per class recommended)
- Increase number of epochs
- Try different model architectures
- Check for data quality issues

**3. Import Errors**
```bash
# Reinstall requirements
pip install --upgrade -r requirements.txt
```

**4. Slow Training**
```python
# Enable mixed precision
Config.USE_MIXED_PRECISION = True

# Increase num_workers
Config.NUM_WORKERS = 4  # adjust based on CPU cores
```

## ğŸ“ Citation

If you use this pipeline in your research, please cite:

```bibtex
@software{spice_classification_2024,
  author = {Your Name},
  title = {Spice Image Classification Pipeline},
  year = {2024},
  url = {https://github.com/yourusername/spice-classification}
}
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“§ Contact

For questions or support, please open an issue on GitHub.

---

**Made with â¤ï¸ for the Computer Vision Community**
